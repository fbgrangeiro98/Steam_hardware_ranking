{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import pyodbc \n",
    "import urllib\n",
    "import sqlalchemy\n",
    "import os\n",
    "import bs4\n",
    "import html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##cria conexão com o banco\n",
    "\n",
    "DRIVER = 'SQL SERVER'\n",
    "SERVER = 'DESKTOP-2VSV2T8'\n",
    "DB_NAME = 'Projeto_Steam'\n",
    "\n",
    "conn = pyodbc.connect(f\"\"\"\n",
    "        DRIVER={{{DRIVER}}};\n",
    "        SERVER={SERVER};\n",
    "        DATABASE={DB_NAME};\n",
    "        Trust_Connection=yes;\n",
    "                        \"\"\")\n",
    "\n",
    "##cria cursor para execução dos comandos em sql\n",
    "cursor = conn.cursor()\n",
    "\n",
    "##comita para salvar as alterações\n",
    "cursor.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##valida numero de paginas da api com os jogos\n",
    "steam_spy = f'https://steamspy.com/api.php?request=all&page={63}'\n",
    "novo_request = requests.get(steam_spy)\n",
    "\n",
    "\n",
    "\n",
    "if novo_request.status_code == 200:\n",
    "    print('true')\n",
    "else:\n",
    "     print('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##extrai dados da api\n",
    "\n",
    "pagination = 1\n",
    "lista_de_jogos = []\n",
    "\n",
    "# steam_spy = 'https://steamspy.com/api.php?request=all&page=1'\n",
    "# novo_request = requests.get(steam_spy)\n",
    "# df = json.loads(novo_request.text)\n",
    "\n",
    "\n",
    "while True :\n",
    "    try:\n",
    "        steam_spy = f'https://steamspy.com/api.php?request=all&page={pagination}'\n",
    "        novo_request = requests.get(steam_spy)\n",
    "        df =  json.loads(novo_request.text) \n",
    "        for x in df:\n",
    "            lista_de_jogos.append((df[x].get('appid'), df[x].get('name'),df[x].get('developer'),df[x].get('publisher'),df[x].get('ccu'),df[x].get('positive'),df[x].get('negative'),df[x].get('languages')))\n",
    "        \n",
    "        pagination = pagination + 1\n",
    "    except:\n",
    "        print('carga finalizada')\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##tranforma em df e renomeia colunas\n",
    "df = pd.DataFrame(lista_de_jogos)\n",
    "df.columns = ['appid','nome','desenvolvedor','distribuidora','ccu','positivo','negativo', 'idiomas']\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##cria tabela de aplicativos resumida\n",
    "cursor.execute('DROP TABLE IF EXISTS Jogos CREATE TABLE Jogos (Appid bigint, Nome varchar(1000))')\n",
    "\n",
    "##insere dados dos jogos na tabela\n",
    "for index,row in df.iterrows():\n",
    "    cursor.execute(f'insert into Jogos  (appid,nome) values(?,?)',row.appid,row.nome)\n",
    "    \n",
    "\n",
    "\n",
    "##cria tabela fact jogos\n",
    "cursor.execute('DROP TABLE IF EXISTS Fact_Jogos CREATE TABLE Fact_Jogos (Appid bigint, Nome varchar(1000),desenvolvedor varchar(1000),distribuidora varchar(1000),ccu bigint, positivo bigint, negativo bigint)')\n",
    "cursor.commit()\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    cursor.execute(f'insert into Fact_Jogos  (appid,nome,desenvolvedor,distribuidora,ccu,positivo,negativo) values(?,?,?,?,?,?,?)',row.appid,row.nome,row.desenvolvedor,row.distribuidora,row.ccu,row.positivo,row.negativo)\n",
    "\n",
    "cursor.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##le dados de uma tabela\n",
    "pd.read_sql_query('select * from Fact_Jogos',con=conn) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PARTE 2 DADOS DAS PLACAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz o download do conteúdo da página\n",
    "url = \"https://store.steampowered.com/hwsurvey/videocard/\"\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "# Cria um objeto BeautifulSoup para analisar o conteúdo HTML\n",
    "soup = bs4.BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "data_list = []\n",
    "for i in range(0,2,1) :\n",
    "# Encontra todas as divs com a classe \"substats_row row_0\"\n",
    "    divs = soup.find_all(\"div\", class_=f\"substats_row row_{i}\")\n",
    "\n",
    "    # Extrai os dados de cada div\n",
    "    for div in divs:\n",
    "        data = div.get_text(separator='|', strip=True)\n",
    "        data_list.append(data)\n",
    "\n",
    "# transforma em dataframe\n",
    "df = pd.DataFrame(data_list,columns=['A'])\n",
    "#separa as colunas do dataframe\n",
    "df = df['A'].str.split('|',expand=True)\n",
    "\n",
    "#renomeia colunas\n",
    "df.columns = ['Placa','DEZ','JAN','FEV','MAR','ABR','RESULTADO']\n",
    "\n",
    "# #identifica quais linhas quero remover\n",
    "# remover = df.query('Placa.str.contains(\"Direct\")').index\n",
    "\n",
    "# #remove registros\n",
    "# df.drop(remover,axis=0,inplace=True)\n",
    "\n",
    "substituicoes = {'%':'','-':'0'}\n",
    "\n",
    "# df[['DEZ','JAN','FEV','MAR','ABR']].replace(substituicoes,regex=True).astype(float)/100\n",
    "\n",
    "df.iloc[0:,1:].replace(substituicoes,regex=True,inplace=True)\n",
    "\n",
    "df.drop(columns='RESULTADO')\n",
    "\n",
    "df['RESULTADO'] = df['ABR'].astype(float)  - df['MAR'].astype(float)\n",
    "\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Faz o download do conteúdo da página parte 1\n",
    "url = \"https://store.steampowered.com/hwsurvey/videocard/\"\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "# Cria um objeto BeautifulSoup para analisar o conteúdo HTML\n",
    "soup = bs4.BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "data_list1 = []\n",
    "for i in range(0,2,1) :\n",
    "# Encontra todas as divs com a classe \"substats_row row_0\"\n",
    "    divs = soup.find_all(\"div\", class_=f\"substats_row row_0\")\n",
    "\n",
    "    # Extrai os dados de cada div\n",
    "    for div in divs:\n",
    "        data = div.get_text(separator='|', strip=True)\n",
    "        data_list1.append(data)\n",
    "\n",
    "# transforma em dataframe\n",
    "df = pd.DataFrame(data_list1,columns=['A'])\n",
    "#separa as colunas do dataframe\n",
    "df = df['A'].str.split('|',expand=True)\n",
    "\n",
    "#renomeia colunas\n",
    "df.columns = ['Placa','MES_1','MES_2','MES_3','MES_4','MES_ATUAL','RESULTADO']\n",
    "\n",
    "#identifica quais linhas quero remover\n",
    "remover = df.query('Placa.str.contains(\"Direct\")').index\n",
    "\n",
    "#remove registros\n",
    "df.drop(remover,axis=0,inplace=True)\n",
    "\n",
    "substituicoes = {'%':'','-':'0'}\n",
    "\n",
    "# df[['DEZ','JAN','FEV','MAR','ABR']].replace(substituicoes,regex=True).astype(float)/100\n",
    "\n",
    "df.iloc[0:,1:].replace(substituicoes,regex=True,inplace=True)\n",
    "\n",
    "df.drop(columns='RESULTADO')\n",
    "\n",
    "df['RESULTADO'] = df['MES_ATUAL'].astype(float)  - df['MES_4'].astype(float)\n",
    "\n",
    "df1 = df\n",
    "\n",
    "## Faz o download do conteúdo da página parte 2\n",
    "url = \"https://store.steampowered.com/hwsurvey/videocard/\"\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "# Cria um objeto BeautifulSoup para analisar o conteúdo HTML\n",
    "soup = bs4.BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "data_list2 = []\n",
    "for i in range(0,2,1) :\n",
    "# Encontra todas as divs com a classe \"substats_row row_0\"\n",
    "    divs = soup.find_all(\"div\", class_=f\"substats_row row_1\")\n",
    "\n",
    "    # Extrai os dados de cada div\n",
    "    for div in divs:\n",
    "        data = div.get_text(separator='|', strip=True)\n",
    "        data_list2.append(data)\n",
    "\n",
    "# transforma em dataframe\n",
    "df = pd.DataFrame(data_list2,columns=['A'])\n",
    "#separa as colunas do dataframe\n",
    "df = df['A'].str.split('|',expand=True)\n",
    "\n",
    "#renomeia colunas\n",
    "df.columns = ['Placa','MES_1','MES_2','MES_3','MES_4','MES_ATUAL','RESULTADO']\n",
    "\n",
    "#identifica quais linhas quero remover\n",
    "remover = df.query('Placa.str.contains(\"Direct\")').index\n",
    "\n",
    "#remove registros\n",
    "df.drop(remover,axis=0,inplace=True)\n",
    "\n",
    "substituicoes = {'%':'','-':'0'}\n",
    "\n",
    "# df[['DEZ','JAN','FEV','MAR','ABR']].replace(substituicoes,regex=True).astype(float)/100\n",
    "\n",
    "df.iloc[0:,1:].replace(substituicoes,regex=True,inplace=True)\n",
    "\n",
    "df.drop(columns='RESULTADO')\n",
    "\n",
    "df['RESULTADO'] = df['MES_ATUAL'].astype(float)  - df['MES_4'].astype(float)\n",
    "\n",
    "df2 = df\n",
    "\n",
    "\n",
    "##combina as duas listas\n",
    "dados_combinados = [item for pair in zip(data_list1, data_list2) for item in pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transforma em dataframe\n",
    "df = pd.DataFrame(dados_combinados,columns=['A'])\n",
    "#separa as colunas do dataframe\n",
    "df = df['A'].str.split('|',expand=True)\n",
    "\n",
    "# #renomeia colunas\n",
    "df.columns = ['Placa','ABR','MAIO','JUN','JUL', 'AUG','RESULTADO']\n",
    "\n",
    "##remove as 6 primeiras linhas\n",
    "df = df.drop(index=range(6)).reset_index(drop=True)\n",
    "\n",
    "# # #identifica quais linhas quero remover\n",
    "remover = df.query('Placa.str.contains(\"NVIDIA GeForce GTX 1650\")').index\n",
    "\n",
    "\n",
    "\n",
    "##MARCA A PARTIR DE ONDE QUERO EXCLUIR\n",
    "ultima_linha = remover[3]\n",
    "df = df[:ultima_linha]\n",
    "\n",
    "##CRIA DICIONARIO COM AS SUBSTITUICOES QUE QUERO FAZER NAS COLUNAS DO DATAFRAME\n",
    "substituicoes = {'%':'','-':'0'}\n",
    "df.iloc[0:,1:].replace(substituicoes,regex=True,inplace=True)\n",
    "\n",
    "\n",
    "##CRIA NOVA COLUNA DE RESULTADO FLOAT\n",
    "df.drop(columns='RESULTADO')\n",
    "df['RESULTADO'] = df['AUG'].astype(float)  - df['JUL'].astype(float)\n",
    "\n",
    "##SEPARA POR MARCA\n",
    "marca = df['Placa'].str.split(' ',n=1,expand=True)[0]\n",
    "placa = df['Placa'].str.split(' ',n=1,expand=True)[1]\n",
    "df['Marca'] = marca\n",
    "df['Placa'] = placa\n",
    "\n",
    "##corrigi classificação intel\n",
    "df['Marca'].replace('Intel(R)', 'INTEL',inplace=True)\n",
    "df['Marca'].replace('Other', 'OUTRAS', inplace=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##cria tabela para as informações das placas\n",
    "\n",
    "cursor.execute('drop table if exists tb_placas_de_video_resultado  create table Tb_Placas_De_Video_Resultado (Marca varchar(100), placa varchar(200), FEV NUMERIC(20,2),MAR NUMERIC(20,2),ABR NUMERIC(20,2),MAIO NUMERIC(20,2),JUNHO NUMERIC(20,2),RESULTADO NUMERIC(20,2))')\n",
    "cursor.commit()\n",
    "\n",
    "##Insere dados nas tabelas\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    cursor.execute(f'insert into tb_placas_de_video_resultado(Marca,placa,FEV,MAR,ABR,MAIO,JUNHO,RESULTADO) values(?,?,?,?,?,?,?,?)',row[7],row[0],row[1],row[2],row[3],row[4],row[5],row[6])\n",
    "\n",
    "cursor.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##ATUALIZACAO  MENSAL RANKING GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##extrai ultimo mês\n",
    "\n",
    "df = pd.DataFrame(dados_combinados,columns=['A'])\n",
    "\n",
    "#separa as colunas do dataframe\n",
    "df = df['A'].str.split('|',expand=True)\n",
    "\n",
    "df.columns = ['Placa','MES_1','MES_2','MES_3','MES_4','MES_ATUAL','RESULTADO']\n",
    "\n",
    "##remove as 6 primeiras linhas\n",
    "df = df.drop(index=range(6)).reset_index(drop=True)\n",
    "\n",
    "# # #identifica quais linhas quero remover\n",
    "remover = df.query('Placa.str.contains(\"NVIDIA GeForce GTX 1650\")').index\n",
    "\n",
    "\n",
    "\n",
    "##MARCA A PARTIR DE ONDE QUERO EXCLUIR\n",
    "ultima_linha = remover[3]\n",
    "df = df[:ultima_linha]\n",
    "\n",
    "##LIMPA CARACETER %\n",
    "substituicoes = {'%':'','-':'0'}\n",
    "df.iloc[0:,1:].replace(substituicoes,regex=True,inplace=True)\n",
    "\n",
    "\n",
    "##corrigi coluna de resultado\n",
    "df.drop(columns='RESULTADO')\n",
    "df['RESULTADO'] = df['MES_ATUAL'].astype(float)  - df['MES_4'].astype(float)\n",
    "\n",
    "##SEPARA POR MARCA\n",
    "marca = df['Placa'].str.split(' ',n=1,expand=True)[0]\n",
    "placa = df['Placa'].str.split(' ',n=1,expand=True)[1]\n",
    "df['Marca'] = marca\n",
    "df['Placa'] = placa\n",
    "\n",
    "##corrigi classificação intel\n",
    "df['Marca'].replace('Intel(R)', 'INTEL',inplace=True)\n",
    "df['Marca'].replace('Other', 'OUTRAS', inplace=True)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ADICIONA TABELA DO MES\n",
    "cursor.execute('alter table tb_placas_de_video_resultado add  AGOSTO NUMERIC(20,2)')\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CRIA TABELA TEMPORARIA PARA ARMAZENAR O RESULTADO DO  MES\n",
    "cursor.execute('drop table if exists tb_placas_de_video_resultado_temp create table Tb_Placas_De_Video_Resultado_temp (placa varchar(200), MES_ATUAL NUMERIC(20,2),RESULTADO_MES NUMERIC(20,2))')\n",
    "cursor.commit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insere na tabela os dados do mês\n",
    "for index,row in df.iterrows():\n",
    "    cursor.execute(f'insert into tb_placas_de_video_resultado_temp(placa,MES_ATUAL,RESULTADO_MES) values(?,?,?)',row.Placa,row.MES_ATUAL,row.RESULTADO)\n",
    "\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##atualiza tabela principal\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "               update tb_placas_de_video_resultado_temp\n",
    "               set placa = 'Outras'\n",
    "               where placa is null\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"update tb_placas_de_video_resultado \n",
    "                  set AGOSTO = MES_ATUAL, RESULTADO = RESULTADO_MES\n",
    "                  FROM tb_placas_de_video_resultado a\n",
    "                  inner join tb_placas_de_video_resultado_temp b  on a.placa = b.placa   \"\"\")\n",
    "cursor.commit()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PARTE 3 PROCESSADOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz o download do conteúdo da página\n",
    "url = \"https://store.steampowered.com/hwsurvey/processormfg/\"\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "# Cria um objeto BeautifulSoup para analisar o conteúdo HTML\n",
    "soup = bs4.BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "data_list = []\n",
    "for i in range(0,2,1) :\n",
    "# Encontra todas as divs com a classe \"substats_row row_0\"\n",
    "    divs = soup.find_all(\"div\", class_=f\"substats_row row_{i}\")\n",
    "\n",
    "    # Extrai os dados de cada div\n",
    "    for div in divs:\n",
    "        data = div.get_text(separator='|', strip=True)\n",
    "        data_list.append(data)\n",
    "\n",
    "# transforma em dataframe\n",
    "df = pd.DataFrame(data_list,columns=['A'])\n",
    "\n",
    "##splita\n",
    "df = df['A'].str.split('|',expand=True)\n",
    "\n",
    "##renomeia as colunas \n",
    "df.columns = ['Marca', 'MES_1','MES_2','MES_3','MES_4','MES_ATUAL', 'RESULTADO']\n",
    "\n",
    "##LIMPA CARACETER %\n",
    "substituicoes = {'%':'','-':'0'}\n",
    "\n",
    "\n",
    "\n",
    "df.iloc[0:,1:].replace(substituicoes,regex=True,inplace=True)\n",
    "\n",
    "df.drop(columns='RESULTADO')\n",
    "\n",
    "df['RESULTADO'] = df['MES_ATUAL'].astype(float)  - df['MES_4'].astype(float)\n",
    "\n",
    "df\n",
    "\n",
    "##filtra para achar somente as linhas que contem as marcas amd e intel\n",
    "df = df.query(\"Marca == 'GenuineIntel' or Marca == 'AuthenticAMD' or Marca == 'MicrosoftXTA'\").reset_index()\n",
    "\n",
    "#seleciona somente o total por processador\n",
    "df.drop(2,inplace=True)\n",
    "df = df.iloc[0:3]\n",
    "\n",
    "df = df.replace('GenuineIntel', 'INTEL')\n",
    "df = df.replace('AuthenticAMD', 'AMD')\n",
    "df = df.replace('MicrosoftXTA', 'Outros')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##cria tabela para as informações de processadores\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('drop table if exists tb_processadores  create table tb_processadores (MARCA varchar(200), MAR NUMERIC(20,2),ABRIL NUMERIC(20,2),MAIO NUMERIC(20,2),JUNHO NUMERIC(20,2),JULHO NUMERIC(20,2),RESULTADO NUMERIC(20,2))')\n",
    "cursor.commit()\n",
    "\n",
    "\n",
    "##insere dados na tabela\n",
    "for index,row in df.iterrows():\n",
    "    cursor.execute(f'insert into tb_processadores  (MARCA,MAR,ABRIL,MAIO,JUNHO,JULHO,RESULTADO) values(?,?,?,?,?,?,?)',row.Marca,row.MAR,row.ABRIL,row.MAIO,row.JUNHO,row.JULHO,row.RESULTADO)\n",
    "\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATUALIZACAO MENSAL RANKING CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATUALIZACAO MENSAL \n",
    "\n",
    "##ADICIONA COLUNA  DO MES\n",
    "cursor.execute('alter table tb_processadores add  AGOSTO NUMERIC(20,2)')\n",
    "cursor.commit()\n",
    "\n",
    "##CRIA TABELA TEMPORARIA PARA ARMAZENAR O RESULTADO DO  MES\n",
    "cursor.execute('drop table if exists tb_processadores_temp create table tb_processadores_temp (MARCA varchar(200), MES_ATUAL NUMERIC(20,2),RESULTADO_MES NUMERIC(20,2))')\n",
    "cursor.commit()\n",
    "\n",
    "##insere na tabela os dados do mês\n",
    "for index,row in df.iterrows():\n",
    "    cursor.execute(f'insert into tb_processadores_temp(MARCA,MES_ATUAL,RESULTADO_MES) values(?,?,?)',row.Marca,row.MES_ATUAL,row.RESULTADO)\n",
    "cursor.commit()\n",
    "\n",
    "\n",
    "##atualiza tabela principal -- lembrar de mudar o nome do mês\n",
    "cursor.execute(\"\"\"update tb_processadores\n",
    "                  set AGOSTO = MES_ATUAL, \n",
    "                      RESULTADO = RESULTADO_MES\n",
    "                  FROM tb_processadores a\n",
    "                  inner join tb_processadores_temp b  on a.marca = b.marca   \"\"\")\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##top jogos mais vendidos\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extrair_top_100_jogos():\n",
    "    # URL da página com os top 100 jogos da Steam\n",
    "    url = 'https://store.steampowered.com/search/?filter=topsellers'\n",
    "\n",
    "    # Fazendo a requisição HTTP\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Verificando se a requisição foi bem-sucedida\n",
    "    if response.status_code == 200:\n",
    "        # Criando o objeto BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Encontrando a div que contém a lista de jogos\n",
    "        games_div = soup.find('div', {'id': 'search_resultsRows'})\n",
    "\n",
    "        # Iterando sobre os elementos da lista de jogos\n",
    "        for game in games_div.find_all('a', {'class': 'search_result_row'}):\n",
    "            # Extraindo o nome do jogo\n",
    "            game_name = game.find('span', {'class': 'title'}).text.strip()\n",
    "            print(game_name)\n",
    "\n",
    "extrair_top_100_jogos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
